{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #for webscraping\n",
    "import requests               #to get the webpage\n",
    "import re                     #for regular expression matching\n",
    "\n",
    "base_url = 'https://pitchfork.com'\n",
    "\n",
    "#use this page to get the urls for all the best album lists \n",
    "page_name = base_url + '/features/lists-and-guides/'\n",
    "#request the page\n",
    "page = requests.get(page_name)\n",
    "#make the soup\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017 list added manually\n",
    "lists = ['/features/lists-and-guides/the-50-best-albums-of-2017/']\n",
    "\n",
    "#get all links for 50 best albums of the year\n",
    "#matching for the regular expression -50-\n",
    "for link in soup.findAll('a', attrs={'href':re.compile(r'-50-')}):\n",
    "    lists.append(link['href'])\n",
    "\n",
    "#remove duplicates\n",
    "lists = list(set(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_titles(webpage):\n",
    "    \"\"\"\n",
    "    quick helper function to extract album titles from \n",
    "    pitchfork best album of the year lists\n",
    "    @webpage is the page where the albums are listed\n",
    "    returns a list of album titles\n",
    "    \"\"\"\n",
    "    page = requests.get(webpage) #request the page\n",
    "    soup = BeautifulSoup(page.content) #make the soup\n",
    "    #extract the album titles\n",
    "    albums = soup.findAll('h2', {'class' : 'list-blurb__work-title'})\n",
    "    #add the album titles to the list\n",
    "    return([t.get_text() for t in albums])\n",
    "\n",
    "#initalize list to store info\n",
    "album_title = [] \n",
    "\n",
    "#best album link years\n",
    "years = range(2013, 2019)\n",
    "#for each year\n",
    "for year in years:\n",
    "    #filter our list of links for the year\n",
    "    new_page = base_url + [l for l in lists if str(year) in l][0]\n",
    "    album_title += get_album_titles(new_page)\n",
    "    #pitchfork uses a separate web page for every 10 albums\n",
    "    for next_page in range(2, 6):\n",
    "        #get the next page\n",
    "        next_page = new_page + '?page=%s' % next_page\n",
    "        album_title += get_album_titles(next_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #to create a data frame\n",
    "\n",
    "#create a one column df using the album titles\n",
    "album_df = pd.DataFrame({'album_title' : album_title})\n",
    "#add the year and rank for each album\n",
    "album_df['year'] = [year for year in years for i in range(50)]\n",
    "album_df['rank'] = (list(range(50, 0, -1)) * len(years))\n",
    "#save as a csv file\n",
    "album_df.to_csv(\"data/pitchfork_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 #to import data from the data base\n",
    "from functools import reduce #help joining data frames\n",
    "\n",
    "con = sqlite3.connect(\"data/pitchfork.db\")\n",
    "#get review data\n",
    "reviews = pd.read_sql('SELECT * FROM reviews', con) \n",
    "#get genre, label, content (text of review)\n",
    "genres = pd.read_sql('SELECT * FROM genres', con)\n",
    "labels = pd.read_sql('SELECT * FROM labels', con)\n",
    "content = pd.read_sql('SELECT * FROM content', con)\n",
    "con.close()\n",
    "\n",
    "#get word count from review\n",
    "content['word_count'] = content['content'].apply(lambda x: len(x.split()))\n",
    "\n",
    "#data frames to join\n",
    "dfs = [reviews, genres, labels, content]\n",
    "#join and create one data frame\n",
    "reviews_final = reduce(lambda left, right: pd.merge(left, right, on='reviewid'), dfs)\n",
    "#save as a csv file\n",
    "reviews_final.to_csv(\"data/pitchfork_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the top 50 lists with the review data\n",
    "#review album titles are all lower case\n",
    "album_df['album_title_lower'] = album_df['album_title'].str.lower()\n",
    "final_album_df = pd.merge(reviews_final, album_df,  \n",
    "                          how='left', \n",
    "                          left_on= ['title', 'pub_year'], \n",
    "                          right_on = ['album_title_lower', 'year'])\n",
    "final_album_df.to_csv(\"data/pitchfork50_with_reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.6)",
   "language": "python",
   "name": "pyt36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
